{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      RowNumber  CustomerId         Surname  CreditScore Geography  Gender  \\\n",
      "0             1    15634602        Hargrave          619    France  Female   \n",
      "1             2    15647311            Hill          608     Spain  Female   \n",
      "2             3    15619304            Onio          502    France  Female   \n",
      "3             4    15701354            Boni          699    France  Female   \n",
      "4             5    15737888        Mitchell          850     Spain  Female   \n",
      "5             6    15574012             Chu          645     Spain    Male   \n",
      "6             7    15592531        Bartlett          822    France    Male   \n",
      "7             8    15656148          Obinna          376   Germany  Female   \n",
      "8             9    15792365              He          501    France    Male   \n",
      "9            10    15592389              H?          684    France    Male   \n",
      "10           11    15767821          Bearce          528    France    Male   \n",
      "11           12    15737173         Andrews          497     Spain    Male   \n",
      "12           13    15632264             Kay          476    France  Female   \n",
      "13           14    15691483            Chin          549    France  Female   \n",
      "14           15    15600882           Scott          635     Spain  Female   \n",
      "15           16    15643966         Goforth          616   Germany    Male   \n",
      "16           17    15737452           Romeo          653   Germany    Male   \n",
      "17           18    15788218       Henderson          549     Spain  Female   \n",
      "18           19    15661507         Muldrow          587     Spain    Male   \n",
      "19           20    15568982             Hao          726    France  Female   \n",
      "20           21    15577657        McDonald          732    France    Male   \n",
      "21           22    15597945        Dellucci          636     Spain  Female   \n",
      "22           23    15699309       Gerasimov          510     Spain  Female   \n",
      "23           24    15725737          Mosman          669    France    Male   \n",
      "24           25    15625047             Yen          846    France  Female   \n",
      "25           26    15738191         Maclean          577    France    Male   \n",
      "26           27    15736816           Young          756   Germany    Male   \n",
      "27           28    15700772         Nebechi          571    France    Male   \n",
      "28           29    15728693      McWilliams          574   Germany  Female   \n",
      "29           30    15656300        Lucciano          411    France    Male   \n",
      "...         ...         ...             ...          ...       ...     ...   \n",
      "9970       9971    15587133        Thompson          518    France    Male   \n",
      "9971       9972    15721377            Chou          833    France  Female   \n",
      "9972       9973    15747927           Ch'in          758    France    Male   \n",
      "9973       9974    15806455          Miller          611    France    Male   \n",
      "9974       9975    15695474          Barker          583    France    Male   \n",
      "9975       9976    15666295           Smith          610   Germany    Male   \n",
      "9976       9977    15656062         Azikiwe          637    France  Female   \n",
      "9977       9978    15579969         Mancini          683    France  Female   \n",
      "9978       9979    15703563           P'eng          774    France    Male   \n",
      "9979       9980    15692664          Diribe          677    France  Female   \n",
      "9980       9981    15719276            T'ao          741     Spain    Male   \n",
      "9981       9982    15672754        Burbidge          498   Germany    Male   \n",
      "9982       9983    15768163         Griffin          655   Germany  Female   \n",
      "9983       9984    15656710           Cocci          613    France    Male   \n",
      "9984       9985    15696175  Echezonachukwu          602   Germany    Male   \n",
      "9985       9986    15586914          Nepean          659    France    Male   \n",
      "9986       9987    15581736        Bartlett          673   Germany    Male   \n",
      "9987       9988    15588839         Mancini          606     Spain    Male   \n",
      "9988       9989    15589329         Pirozzi          775    France    Male   \n",
      "9989       9990    15605622        McMillan          841     Spain    Male   \n",
      "9990       9991    15798964      Nkemakonam          714   Germany    Male   \n",
      "9991       9992    15769959     Ajuluchukwu          597    France  Female   \n",
      "9992       9993    15657105     Chukwualuka          726     Spain    Male   \n",
      "9993       9994    15569266          Rahman          644    France    Male   \n",
      "9994       9995    15719294            Wood          800    France  Female   \n",
      "9995       9996    15606229        Obijiaku          771    France    Male   \n",
      "9996       9997    15569892       Johnstone          516    France    Male   \n",
      "9997       9998    15584532             Liu          709    France  Female   \n",
      "9998       9999    15682355       Sabbatini          772   Germany    Male   \n",
      "9999      10000    15628319          Walker          792    France  Female   \n",
      "\n",
      "      Age  Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
      "0      42       2       0.00              1          1               1   \n",
      "1      41       1   83807.86              1          0               1   \n",
      "2      42       8  159660.80              3          1               0   \n",
      "3      39       1       0.00              2          0               0   \n",
      "4      43       2  125510.82              1          1               1   \n",
      "5      44       8  113755.78              2          1               0   \n",
      "6      50       7       0.00              2          1               1   \n",
      "7      29       4  115046.74              4          1               0   \n",
      "8      44       4  142051.07              2          0               1   \n",
      "9      27       2  134603.88              1          1               1   \n",
      "10     31       6  102016.72              2          0               0   \n",
      "11     24       3       0.00              2          1               0   \n",
      "12     34      10       0.00              2          1               0   \n",
      "13     25       5       0.00              2          0               0   \n",
      "14     35       7       0.00              2          1               1   \n",
      "15     45       3  143129.41              2          0               1   \n",
      "16     58       1  132602.88              1          1               0   \n",
      "17     24       9       0.00              2          1               1   \n",
      "18     45       6       0.00              1          0               0   \n",
      "19     24       6       0.00              2          1               1   \n",
      "20     41       8       0.00              2          1               1   \n",
      "21     32       8       0.00              2          1               0   \n",
      "22     38       4       0.00              1          1               0   \n",
      "23     46       3       0.00              2          0               1   \n",
      "24     38       5       0.00              1          1               1   \n",
      "25     25       3       0.00              2          0               1   \n",
      "26     36       2  136815.64              1          1               1   \n",
      "27     44       9       0.00              2          0               0   \n",
      "28     43       3  141349.43              1          1               1   \n",
      "29     29       0   59697.17              2          1               1   \n",
      "...   ...     ...        ...            ...        ...             ...   \n",
      "9970   42       7  151027.05              2          1               0   \n",
      "9971   34       3  144751.81              1          0               0   \n",
      "9972   26       4  155739.76              1          1               0   \n",
      "9973   27       7       0.00              2          1               1   \n",
      "9974   33       7  122531.86              1          1               0   \n",
      "9975   50       1  113957.01              2          1               0   \n",
      "9976   33       7  103377.81              1          1               0   \n",
      "9977   32       9       0.00              2          1               1   \n",
      "9978   40       9   93017.47              2          1               0   \n",
      "9979   58       1   90022.85              1          0               1   \n",
      "9980   35       6   74371.49              1          0               0   \n",
      "9981   42       3  152039.70              1          1               1   \n",
      "9982   46       7  137145.12              1          1               0   \n",
      "9983   40       4       0.00              1          0               0   \n",
      "9984   35       7   90602.42              2          1               1   \n",
      "9985   36       6  123841.49              2          1               0   \n",
      "9986   47       1  183579.54              2          0               1   \n",
      "9987   30       8  180307.73              2          1               1   \n",
      "9988   30       4       0.00              2          1               0   \n",
      "9989   28       4       0.00              2          1               1   \n",
      "9990   33       3   35016.60              1          1               0   \n",
      "9991   53       4   88381.21              1          1               0   \n",
      "9992   36       2       0.00              1          1               0   \n",
      "9993   28       7  155060.41              1          1               0   \n",
      "9994   29       2       0.00              2          0               0   \n",
      "9995   39       5       0.00              2          1               0   \n",
      "9996   35      10   57369.61              1          1               1   \n",
      "9997   36       7       0.00              1          0               1   \n",
      "9998   42       3   75075.31              2          1               0   \n",
      "9999   28       4  130142.79              1          1               0   \n",
      "\n",
      "      EstimatedSalary  Exited  \n",
      "0           101348.88       1  \n",
      "1           112542.58       0  \n",
      "2           113931.57       1  \n",
      "3            93826.63       0  \n",
      "4            79084.10       0  \n",
      "5           149756.71       1  \n",
      "6            10062.80       0  \n",
      "7           119346.88       1  \n",
      "8            74940.50       0  \n",
      "9            71725.73       0  \n",
      "10           80181.12       0  \n",
      "11           76390.01       0  \n",
      "12           26260.98       0  \n",
      "13          190857.79       0  \n",
      "14           65951.65       0  \n",
      "15           64327.26       0  \n",
      "16            5097.67       1  \n",
      "17           14406.41       0  \n",
      "18          158684.81       0  \n",
      "19           54724.03       0  \n",
      "20          170886.17       0  \n",
      "21          138555.46       0  \n",
      "22          118913.53       1  \n",
      "23            8487.75       0  \n",
      "24          187616.16       0  \n",
      "25          124508.29       0  \n",
      "26          170041.95       0  \n",
      "27           38433.35       0  \n",
      "28          100187.43       0  \n",
      "29           53483.21       0  \n",
      "...               ...     ...  \n",
      "9970        119377.36       0  \n",
      "9971        166472.81       0  \n",
      "9972        171552.02       0  \n",
      "9973        157474.10       0  \n",
      "9974         13549.24       0  \n",
      "9975        196526.55       1  \n",
      "9976         84419.78       0  \n",
      "9977         24991.92       0  \n",
      "9978        191608.97       0  \n",
      "9979          2988.28       0  \n",
      "9980         99595.67       0  \n",
      "9981         53445.17       1  \n",
      "9982        115146.40       1  \n",
      "9983        151325.24       0  \n",
      "9984         51695.41       0  \n",
      "9985         96833.00       0  \n",
      "9986         34047.54       0  \n",
      "9987          1914.41       0  \n",
      "9988         49337.84       0  \n",
      "9989        179436.60       0  \n",
      "9990         53667.08       0  \n",
      "9991         69384.71       1  \n",
      "9992        195192.40       0  \n",
      "9993         29179.52       0  \n",
      "9994        167773.55       0  \n",
      "9995         96270.64       0  \n",
      "9996        101699.77       0  \n",
      "9997         42085.58       1  \n",
      "9998         92888.52       1  \n",
      "9999         38190.78       0  \n",
      "\n",
      "[10000 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "#import necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import pandas as pd  \n",
    "import seaborn as sns \n",
    "\n",
    "# import data\n",
    "data = pd.read_csv(\"datasets-35847-51854-Churn Modeling.csv\")\n",
    "data.head()\n",
    "\n",
    "\n",
    "print(data)\n",
    "#defining functions \n",
    "def calc_error_r(classi, X_train, X_test, y_train, y_test):\n",
    "    classi.fit(X_train, y_train)\n",
    "    y_test_predict = classi.predict(X_test)\n",
    "    print(\"r square: \", format(r2_score(y_test, y_test_predict)))\n",
    "    print(\"squared loss: \", format(mean_squared_error(y_test, y_test_predict)))\n",
    "\n",
    "def calc_score(classi, X_train, X_test, y_train, y_test):\n",
    "    classi.fit(X_train, y_train)\n",
    "    print(classi.score(X_test, y_test))\n",
    "    \n",
    "\n",
    "def Average(lst): \n",
    "    return sum(lst) / len(lst) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpearmanrResult(correlation=0.0030114427900058186, pvalue=0.7633326620455019)\n",
      "SpearmanrResult(correlation=-0.007974044311824222, pvalue=0.4252667030635392)\n",
      "SpearmanrResult(correlation=0.001133174187231753, pvalue=0.9097901093099146)\n",
      "SpearmanrResult(correlation=0.005686570567648804, pvalue=0.5696340276861511)\n",
      "SpearmanrResult(correlation=0.012567727105426257, pvalue=0.20887488379726135)\n",
      "SpearmanrResult(correlation=-0.003801819664491181, pvalue=0.7038446015276565)\n",
      "SpearmanrResult(correlation=0.024262340713124095, pvalue=0.015254163694324864)\n",
      "SpearmanrResult(correlation=0.001236524378517163, pvalue=0.9016026735590865)\n",
      "SpearmanrResult(correlation=-0.023289396606662873, pvalue=0.019860952565325888)\n",
      "SpearmanrResult(correlation=-0.1561282781889051, pvalue=1.3482685164858008e-55)\n",
      "SpearmanrResult(correlation=0.011778003481770119, pvalue=0.2389186359196331)\n",
      "      principal component 1  principal component 2  principal component 3  \\\n",
      "0             -76157.145982           -7194.761639              30.782497   \n",
      "1               8266.910414          -11846.105622              42.570441   \n",
      "2              83998.633333           -7340.133437             149.305857   \n",
      "3             -76741.325977             304.770460             -49.200299   \n",
      "4              47245.526441           24749.993710            -198.940235   \n",
      "5              41014.447451          -46622.077457               5.771710   \n",
      "6             -83246.455029           83815.623438            -171.989380   \n",
      "7              39939.867222          -16203.833470             274.852120   \n",
      "8              63414.025932           30165.600372             150.231324   \n",
      "9              55739.668824           32792.310364             -32.840840   \n",
      "10             23907.573469           21831.725227             122.822781   \n",
      "11            -78095.462376           17688.728972             152.835681   \n",
      "12            -81988.501700           67666.362864             173.963451   \n",
      "13            -69205.851406          -96433.343588             100.554388   \n",
      "14            -78906.107944           28095.564256              14.866144   \n",
      "15             63664.882141           40830.531694              35.268336   \n",
      "16             48570.351975           99063.746688              -1.682157   \n",
      "17            -82909.131373           79485.130771             100.987917   \n",
      "18            -71704.416568          -64357.529928              62.642714   \n",
      "19            -79778.048289           39289.275687             -76.111150   \n",
      "20            -70756.853048          -76522.039809             -82.389318   \n",
      "21            -73267.668992          -44288.972995              13.686199   \n",
      "22            -74793.069767          -24706.364516             139.737457   \n",
      "23            -83368.775472           85385.916090             -18.987260   \n",
      "24            -69457.594711          -93201.502747            -196.431692   \n",
      "25            -74358.578048          -30284.227436              72.717619   \n",
      "26             65580.024068          -65055.215778            -105.057257   \n",
      "27            -81043.189955           55530.755295              78.938084   \n",
      "28             64675.191674            4940.429925              77.161930   \n",
      "29            -20357.536864           45162.451732             239.475573   \n",
      "...                     ...                    ...                    ...   \n",
      "9970           75813.880596          -13439.976649             133.208522   \n",
      "9971           73215.045794          -60880.528872            -181.971936   \n",
      "9972           84564.263376          -65091.070972            -106.881097   \n",
      "9973          -71798.440621          -63150.476381              38.637318   \n",
      "9974           39186.099021           89855.582066              68.187514   \n",
      "9975           44847.232628          -93235.039086              40.661442   \n",
      "9976           25593.729768           17711.569631              13.826595   \n",
      "9977          -82087.055411           68931.590803             -33.034418   \n",
      "9978           23589.033111          -89958.482782            -123.534995   \n",
      "9979            5955.103296           97859.985133             -26.091614   \n",
      "9980           -2146.421169             328.871463             -90.492286   \n",
      "9981           71703.153629           52371.732456             153.380601   \n",
      "9982           61645.299197          -10299.870099              -3.914422   \n",
      "9983          -72275.963297          -57020.186691              36.658657   \n",
      "9984           10315.535980           49344.966207              48.783343   \n",
      "9985           46959.622362            6925.056230              -8.003381   \n",
      "9986          101641.313802           74160.175448             -21.262325   \n",
      "9987           95883.913502          105942.169070              45.777022   \n",
      "9988          -80196.341317           44659.198876            -125.094948   \n",
      "9989          -70092.822482          -85046.646093            -191.416218   \n",
      "9990          -44949.286072           43062.435754             -63.763292   \n",
      "9991            9474.791983           31536.590165              53.726782   \n",
      "9992          -68869.222233         -100754.861924             -76.451085   \n",
      "9993           72830.262586           76798.687009               7.463490   \n",
      "9994          -70998.579683          -73418.820118            -150.386863   \n",
      "9995          -76551.522566           -2131.858089            -121.206376   \n",
      "9996          -18933.550283           -3089.246951             134.336803   \n",
      "9997          -80759.555132           51889.555925             -59.074544   \n",
      "9998           -1965.606234            7070.424053            -121.465759   \n",
      "9999           48687.716195           65879.530979            -140.801213   \n",
      "\n",
      "      principal component 4  \n",
      "0                  3.442026  \n",
      "1                  2.056845  \n",
      "2                  2.616416  \n",
      "3                  0.466172  \n",
      "4                  3.917361  \n",
      "5                  4.954193  \n",
      "6                 11.391299  \n",
      "7                -10.202865  \n",
      "8                  4.662462  \n",
      "9                -12.216123  \n",
      "10                -8.135515  \n",
      "11               -14.654165  \n",
      "12                -4.754978  \n",
      "13               -13.479242  \n",
      "14                -3.611970  \n",
      "15                 5.703946  \n",
      "16                18.691541  \n",
      "17               -14.727905  \n",
      "18                 6.493288  \n",
      "19               -14.586011  \n",
      "20                 2.569884  \n",
      "21                -6.518078  \n",
      "22                -0.590055  \n",
      "23                 7.331466  \n",
      "24                -0.343865  \n",
      "25               -13.549689  \n",
      "26                -3.052129  \n",
      "27                 5.306958  \n",
      "28                 3.745006  \n",
      "29               -10.001844  \n",
      "...                     ...  \n",
      "9970               2.675402  \n",
      "9971              -5.071259  \n",
      "9972             -13.155660  \n",
      "9973             -11.500637  \n",
      "9974              -6.303161  \n",
      "9975              11.024918  \n",
      "9976              -6.087389  \n",
      "9977              -6.655439  \n",
      "9978               1.164452  \n",
      "9979              18.903671  \n",
      "9980              -3.874842  \n",
      "9981               2.593185  \n",
      "9982               6.807126  \n",
      "9983               1.497737  \n",
      "9984              -4.079658  \n",
      "9985              -3.158128  \n",
      "9986               7.499691  \n",
      "9987              -9.582823  \n",
      "9988              -8.570952  \n",
      "9989             -10.353892  \n",
      "9990              -5.750627  \n",
      "9991              13.953773  \n",
      "9992              -2.381805  \n",
      "9993             -11.409735  \n",
      "9994              -9.388295  \n",
      "9995               0.489055  \n",
      "9996              -3.903761  \n",
      "9997              -2.612602  \n",
      "9998               3.136430  \n",
      "9999             -11.200395  \n",
      "\n",
      "[10000 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# preprocessing (apply any of imputation, scaling, feature selection, one hot encoding etc. as you feel necessary) \n",
    "\n",
    "#check if there are any missing values in the data \n",
    "data.isnull().sum()\n",
    "\n",
    "#change string values to int## Male = 0, Female = 1, Germany = 0, Spain = 1, France = 2\n",
    "data[\"Gender\"].replace({\"Male\": 0, \"Female\": 1}, inplace=True)\n",
    "data[\"Geography\"].replace({\"Germany\": 0, \"Spain\": 1, \"France\": 2}, inplace=True)\n",
    "\n",
    "\n",
    "#look for correlations between the feature vectors\n",
    "#the Spearman correlation does not assume that both datasets are normally distributed.\n",
    "from scipy import stats\n",
    "print(stats.spearmanr(data[\"CreditScore\"], data[\"Gender\"]))\n",
    "print(stats.spearmanr(data[\"CreditScore\"], data[\"Age\"]))\n",
    "print(stats.spearmanr(data[\"CreditScore\"], data[\"Tenure\"]))\n",
    "print(stats.spearmanr(data[\"CreditScore\"], data[\"Balance\"]))\n",
    "print(stats.spearmanr(data[\"CreditScore\"], data[\"NumOfProducts\"]))\n",
    "print(stats.spearmanr(data[\"CreditScore\"], data[\"HasCrCard\"]))\n",
    "print(stats.spearmanr(data[\"CreditScore\"], data[\"IsActiveMember\"]))\n",
    "print(stats.spearmanr(data[\"CreditScore\"], data[\"EstimatedSalary\"]))\n",
    "print(stats.spearmanr(data[\"CreditScore\"], data[\"Exited\"]))\n",
    "print(stats.spearmanr(data[\"IsActiveMember\"], data[\"Exited\"]))\n",
    "print(stats.spearmanr(data[\"Balance\"], data[\"EstimatedSalary\"]))\n",
    "\n",
    "\n",
    "#Prepare the data for testing and training set for #Exited\n",
    "X_Exited = data.iloc[:, [3,4,5,6,7,8,9,10,11,12]]\n",
    "\n",
    "#PCA ##################################\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=4)\n",
    "principalComponents = pca.fit_transform(X_Exited)\n",
    "principalDf = pd.DataFrame(data = principalComponents, columns = ['principal component 1', 'principal component 2', 'principal component 3', 'principal component 4'])\n",
    "print(principalDf)\n",
    "\n",
    "#delete 0 values\n",
    "#X.query('line_race != 0')\n",
    "\n",
    "#last collumn \n",
    "y_Exited = data.iloc[:,-1].values\n",
    "\n",
    "# Splitting the data into the Training set and Test set  \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_Exited, X_test_Exited, y_train_Exited, y_test_Exited = train_test_split(X_Exited, y_Exited, test_size=0.2, random_state=10)\n",
    "\n",
    "#############################Prepare the data for testing and training set for #IsActiveMember##############################\n",
    "X_Active = data.iloc[:, [3,6,7,8,9,10,11,13]]\n",
    "#delete 0 values\n",
    "#X.query('line_race != 0')\n",
    "y_Active = data.iloc[:,-3].values\n",
    "\n",
    "# Splitting the data into the Training set and Test set  \n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import Ridge\n",
    "lasso = linear_model.Lasso()\n",
    "\n",
    "X_train_Active, X_test_Active, y_train_Active, y_test_Active = train_test_split(X_Active, y_Active, test_size=0.2, random_state=10)\n",
    "#X_train_Active, X_test_Active, y_train_Active, y_test_Active = cross_validate(ridge, X_Active, y_Active, cv=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import important libs\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "\n",
    "# imputation Exited\n",
    "X_train_Exited = imputer.fit_transform(X_train_Exited)\n",
    "X_test_Exited = imputer.transform(X_test_Exited)\n",
    "\n",
    "# imputation Active\n",
    "X_train_Active = imputer.fit_transform(X_train_Active)\n",
    "X_test_Active = imputer.transform(X_test_Active)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import libs\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "rc = RobustScaler()\n",
    "\n",
    "# scaling Exited \n",
    "X_train_Exited = rc.fit_transform(X_train_Exited)\n",
    "X_test_Exited = rc.transform(X_test_Exited)\n",
    "# scaling Active\n",
    "X_train_Active = rc.fit_transform(X_train_Active)\n",
    "X_test_Active = rc.transform(X_test_Active)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eiden\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#defining the models that are needed for the function\n",
    "#logistic regression ###########################################################################################\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "clf_lg = LogisticRegression(random_state=0, multi_class='auto')#.fit(X_train_Exited, y_train_Exited)\n",
    "\n",
    "#svm#####################################################################################################################\n",
    "from sklearn import svm\n",
    "clf_svm = svm.SVC()\n",
    "clf_svm.fit(X_train_Exited, y_train_Exited)\n",
    "#ridge regression######################################################\n",
    "#We use ridge regression in order in order to shrink features who are not important in a bigger way so that features\n",
    "#who are important have a bigger impact on the end result\n",
    "from sklearn.linear_model import Ridge\n",
    "clf_ridge = Ridge(alpha=1.0)\n",
    "clf_ridge.fit(X_train_Exited, y_train_Exited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eiden\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Eiden\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r square:  -0.18633581412670663\n",
      "squared loss:  0.1975\n",
      "r square:  0.08396854858570757\n",
      "squared loss:  0.1525\n",
      "r square:  0.13909619471885648\n",
      "squared loss:  0.14332240459939952\n"
     ]
    }
   ],
   "source": [
    "#logistic regression##################################################\n",
    "calc_error_r(clf_lg, X_train_Exited, X_test_Exited, y_train_Exited, y_test_Exited)\n",
    "\n",
    "#svm#################################################################\n",
    "calc_error_r(clf_svm, X_train_Exited, X_test_Exited, y_train_Exited, y_test_Exited)\n",
    "\n",
    "#ridge regression#####################################################\n",
    "calc_error_r(clf_ridge, X_train_Exited, X_test_Exited, y_train_Exited, y_test_Exited)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.12788273 0.16592164 0.13979245]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eiden\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\Eiden\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\Eiden\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Eiden\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Eiden\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.85682159 0.85483871 0.85783946]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eiden\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.86169415 0.86196549 0.8555889 ]\n",
      "0.13909619471885648\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eiden\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8475\n",
      "None\n",
      "0.855\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#######faster way##############\n",
    "##############using cross validation#################################\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "scores_lr = []\n",
    "scores_svm = []\n",
    "scores_rf = []\n",
    "\n",
    "print(cross_val_score(clf_ridge, X_train_Exited, y_train_Exited))\n",
    "print(cross_val_score(clf_svm, X_train_Exited, y_train_Exited))\n",
    "print(cross_val_score(RandomForestClassifier(n_estimators=40), X_train_Exited, y_train_Exited))\n",
    "\n",
    "#or#######################without using cross validation####################################\n",
    "print(calc_score(clf_ridge, X_train_Exited, X_test_Exited, y_train_Exited, y_test_Exited))\n",
    "print(calc_score(clf_svm, X_train_Exited, X_test_Exited, y_train_Exited, y_test_Exited))\n",
    "print(calc_score(RandomForestClassifier(n_estimators=40), X_train_Exited, X_test_Exited, y_train_Exited, y_test_Exited))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
